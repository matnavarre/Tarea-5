---
title: "Tarea 5"
author: "Matiás Navarrete - Matiás Pacheco - Jorge Pino"
date: "16 de Noviembre del 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup1, include=FALSE}
library(ggplot2)
library(gridExtra)
```

<Pregunta 2>

```{r 2, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(ggthemes)
library(tidyverse)
library(gridExtra)
if(!require("pacman")) install.packages("pacman")
p_load("tidyverse","tidyquant","ggthemes")
library(quantmod)
library(pdfetch)

#1
tickers <- c("MSFT","AAPL")
acciones <- tq_get(tickers,
                   get = "stock.prices",
                   from = "2000-01-01",
                   to = "2018-08-01",
                   periodicity = "monthly")

#2
#a
acciones1<- acciones%>%filter(acciones$symbol=="MSFT")#datos de msft
acciones2<- acciones%>%filter(acciones$symbol=="AAPL")#datos de apple

retorno2<-function(x){
  if(x=="MSFT"){
    x<-acciones1$open
    z<-acciones1$close
    o<-log(x)-log(z)
    return(o)
  }
  else {
    x<-acciones2$open
    z<-acciones2$close
    o<-log(x)-log(z)
    return(o)
  }
  }
retorno2("MSFT")



#b
rmsft<- retorno2("MSFT")#guardamos los retornos de msft
raapl<- retorno2("AAPL")#guardamos los retornos de apple

retorno2_grafico<-function(x){
  if(x=="MSFT"){
    g1<-acciones1%>%ggplot(aes(x=acciones1$date,y=rmsft))+geom_line()+ 
      ylab("Variación del retorno")+xlab("Tiempo")+ggtitle("Variación del retorno en el tiempo")+theme_economist()
    g2<-acciones1%>%ggplot(aes(x=rmsft,y=))+geom_density(alpha=1)+
     ylab("Densidad")+xlab("Variación")+theme_economist()
    grid.arrange(g1,g2,ncol=2)
  }
  else {
    h1<-acciones2%>%ggplot(aes(x=acciones2$date,y=raapl))+geom_line()+ 
      ylab("Variación del retorno")+xlab("Tiempo")+ggtitle("Variación del retorno en el tiempo")+
    theme_economist()
    h2<-acciones2%>%ggplot(aes(x=raapl,y=))+geom_density(alpha=1)+
      ylab("Densidad")+xlab("Variación")+theme_economist()
    grid.arrange(h1,h2,ncol=2)
  }}
  
retorno2_grafico("MSFT")

#c
Jarque.bera<-function(x){
  if(x=="MSFT"){
    
    
    JB<- function(x){ 
      x<-rmsft
      n<-length(x)
      JBE<- n*((((sum((x-mean(x))^3))/n / ((sqrt(var(x))^3)))^2)/6 + ((((sum((x-mean(x))^4))/n / ((var(x)^2)))-3)^2)/24) 
      print(paste("El valor del test jarque bera es igual a",JBE))
    }
    JB("MSFT")
  }
  else {
    JB<- function(x){ 
      x<-raapl
      n<-length(x)
      JBE<- n*((((sum((x-mean(x))^3))/n / ((sqrt(var(x))^3)))^2)/6 + ((((sum((x-mean(x))^4))/n / ((var(x)^2)))-3)^2)/24) 
      print(paste("El valor del test jarque bera es igual a",JBE))
    }
    JB("raapl")
  }}

Jarque.bera("MSFT")



#función final
función_final<- function(x){
  if(x=="MSFT"){
   retorno2("MSFT")
    retorno2_grafico("MSFT")
    Jarque.bera("MSFT")
  }
  else {
    retorno2("AAPL")
    retorno2_grafico("AAPL")
    Jarque.bera("AAPl")
  }
}

función_final("AAPL")
```

<Pregunta 3>

##a)

```{r a, echo=FALSE, message=FALSE, warning=FALSE}
reps = 10000
n = c(50, 100, 500, 1000)
betas=matrix(NA, nrow = reps, ncol=8)
beta0 = 2
beta1 = 2.5
beta2 = 1

for(j in 1:length(n)){
  x1 = rnorm(n[j],20,1)
  e = rnorm(n[j],0,1)
  x2 = 0.8*x1 + e
  for(i in 1:reps){
    u=rnorm(n[j],0,1)
    y=beta0 + beta1*x1 + beta2*x2 + u
    model=lm(y~x1)
    betas[i,j]=model$coef[1]
    betas[i,j+4]=model$coef[2]
  }
}
betas_df<-data.frame(betas)
means <- apply(betas,2,mean)
```

```{r esp, echo=FALSE, message=FALSE, warning=FALSE}


Eb0 = c(means[[1]], means[[2]],means[[3]],means[[4]])
Eb1 = c(means[[5]], means[[6]],means[[7]],means[[8]])

cat("E(b0) =", Eb0, "\n")
cat("E(b1) =", Eb1, "\n")
```

Aquí se constata que las esperanzas de los parámetros estimados de $\beta_{0}$ y $\beta_{1}$ son distintas al parámetro real. Al aumentar el tamaño muestral si bien $E(\beta_{0})$ va acercandose a su valor real a medida que aumenta $n$, esto no sucede con $E(\beta_{1})$, el cual presenta una esperanza que no tiene un patrón definido.

Las varianzas son las siguientes: 

```{r vars, echo=FALSE, message=FALSE, warning=FALSE}

vars <- apply(betas,2,var)

varb0 = c(vars[[1]], vars[[2]],vars[[3]],vars[[4]])
varb1 = c(vars[[5]], vars[[6]],vars[[7]],vars[[8]])

cat("Var(b0) =", varb0, "\n")
cat("Var(b1) =", varb1, "\n")
```

EL sesgo presente para cada coeficiente según tamaño muestral es: 

```{r sesgo, echo=FALSE, message=FALSE, warning=FALSE}

sesgob0 = c(means[[1]]-2, means[[2]]-2,means[[3]]-2,means[[4]]-2)
sesgob1 = c(means[[5]]-2.5, means[[6]]-2.5, means[[7]]-2.5, means[[8]]-2.5)

cat("Sesgob0 =", sesgob0, "\n")
cat("Sesgob1 =", sesgob1, "\n")

```

Los coeficientes son bastante sesgados, la razón principal de esto es que, probablemente la covarianza entre los regresores es distinta de cero. Evidentemente esto se da porque la variable $x_{2}$ depende de $x_{1}$.  
Se puede apreciar que el sesgo de $\beta_{0}$ va disminuyendo al aumentar el tamaño muestral. Por otro lado el sesgo de $\beta_{1}$ no tiene un patrón de disminición o aumento cuando crece el tamaño muestral. 

##b)

Los gráficos de las distribuciones de los $betas$ con sus respectivos tamaños muestrales son: 

```{r b, echo=FALSE, message=FALSE, warning=FALSE}
g1 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,5], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,5]), sd=sd(betas_df[,5])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=50") 
g2 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,6], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,6]), sd=sd(betas_df[,6])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=100")

g3 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,7], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,7]), sd=sd(betas_df[,7])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=500")

g4 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,8], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,8]), sd=sd(betas_df[,8])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=1000")

grid.arrange(g1, g2, g3, g4, ncol = 2, nrow = 2, top = "Distribución Beta1")
```

Se puede ver claramente que aunque sean sesgados estos coeficientes, al aumentar el tamaño muestral la varianza de estos mismos disminuye bastante (ver límites eje y).

##c)

```{r c1, echo=FALSE, message=FALSE, warning=FALSE}
reps = 10000
n = c(50, 100, 500, 1000)
betas=matrix(NA, nrow = reps, ncol=8)
beta0 = 2
beta1 = 2.5
beta2 = 1

for(j in 1:length(n)){
  x1 = rnorm(n[j],20,1)
  e = rnorm(n[j],0,1)
  x2 = runif(n[j],0,1)
  for(i in 1:reps){
    u=rnorm(n[j],0,1)
    y=beta0 + beta1*x1 + beta2*x2 + u
    model=lm(y~x1)
    betas[i,j]=model$coef[1]
    betas[i,j+4]=model$coef[2]
  }
}
betas_df<-data.frame(betas)
means <- apply(betas,2,mean)
```

Esperanzas: se constata que la esperanza de $\beta_{1}$ es mucho más certera que en el caso anterior. 

```{r esp1, echo=FALSE, message=FALSE, warning=FALSE}

Eb0 = c(means[[1]], means[[2]],means[[3]],means[[4]])
Eb1 = c(means[[5]], means[[6]],means[[7]],means[[8]])

cat("E(b0) =", Eb0, "\n")
cat("E(b1) =", Eb1, "\n")
```

Varianzas: 

```{r var1, echo=FALSE, message=FALSE, warning=FALSE}

vars <- apply(betas,2,var)

varb0 = c(vars[[1]], vars[[2]],vars[[3]],vars[[4]])
varb1 = c(vars[[5]], vars[[6]],vars[[7]],vars[[8]])

cat("Var(b0) =", varb0, "\n")
cat("Var(b1) =", varb1, "\n")
```

Sesgos:

```{r ses1, echo=FALSE, message=FALSE, warning=FALSE}

sesgob0 = c(means[[1]]-2, means[[2]]-2,means[[3]]-2,means[[4]]-2)
sesgob1 = c(means[[5]]-2.5, means[[6]]-2.5, means[[7]]-2.5, means[[8]]-2.5)

cat("Sesgob0 =", sesgob0, "\n")
cat("Sesgob1 =", sesgob1, "\n")


```

Evidentemente, el sesgo de $\beta_{1}$ es mucho menor que en el caso anterior, se podría decir, que en estos casos no hay sesgo, ya que al aumentar el tamaño muestrar este disminuye bastante lo que tiende a cero. Intuitivamente tiene bastante sentido este resultado, debido a que la variable $x_{2}$ sigue una distribución uniforme entre cero y uno, por lo tanto la covarianza entre los regresores es probablemente nula.  

Gráficos: 

```{r c2, echo=FALSE, message=FALSE, warning=FALSE}
g1 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,5], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,5]), sd=sd(betas_df[,5])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=50") 
g2 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,6], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,6]), sd=sd(betas_df[,6])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=100")

g3 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,7], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,7]), sd=sd(betas_df[,7])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=500")

g4 <- ggplot(betas_df) +
  geom_histogram(aes(betas_df[,8], y =..density..), col="black", bins=30) +
  stat_function(fun=dnorm, args=list(mean=mean(betas_df[,8]), sd=sd(betas_df[,8])),
                geom="line",colour="red", size=1) +
  ylab("densidad") + xlab(expression(hat(beta)[1])) + theme_bw() + ggtitle("n=1000")

grid.arrange(g1, g2, g3, g4, ncol = 2, nrow = 2, top = "Distribución Beta1")

```

Evidentemente, en este caso las varianzas son aun mas pequeñas y mientras crece el tamaño muestral, las distribuciones se centran más certeramente en el verdadero valor del del parámetro.
